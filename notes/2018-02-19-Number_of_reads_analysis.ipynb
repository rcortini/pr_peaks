{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mybiotools as mbt\n",
    "import pysam\n",
    "import os\n",
    "import pr_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-02-19 Number of reads analysis\n",
    "I want to perform the same analysis as before, but simply looking at the number of reads corresponding to each of the peaks.\n",
    "\n",
    "The pieces of code below are just copy/pasted from my previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chipseq_bam_location (sample_id,xavi_datadir='/mnt/xavi/data') :\n",
    "    # build the directory name where the files are\n",
    "    d = \"%s/chipseq/samples/%s/alignments\"%(xavi_datadir,sample_id)\n",
    "    # select all files that end with \".bw\" in the directory, and\n",
    "    # then prefer to read the one that is in the directory that has\n",
    "    # \"with_control\"\n",
    "    peakfiles = []\n",
    "    for root,sub,files in os.walk(d) :\n",
    "        for f in files :\n",
    "            if f.endswith (\".bam\") :\n",
    "                peakfiles.append('%s/%s'%(root,f))\n",
    "    fin = None\n",
    "    for peakfile in peakfiles :\n",
    "        if 'with_control' in peakfile :\n",
    "            fin = peakfile\n",
    "            break\n",
    "        else :\n",
    "            fin = peakfile\n",
    "    if fin is None :\n",
    "        warn_message('chipseq_bam_location','Data not found for %s'%sample_id)\n",
    "    return fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Condition :\n",
    "    def __init__(self,name,peak_code,concentration,sample_id) :\n",
    "        self.name = name\n",
    "        self.peak_code = peak_code\n",
    "        self.concentration = concentration\n",
    "        self.sample_id = sample_id\n",
    "        # load the peaks\n",
    "        self.peaks = pr_peaks.load_hcp_peaks(self.peak_code)\n",
    "        # init the BAM file\n",
    "        self.bam_file = chipseq_bam_location(sample_id)\n",
    "        # init the pysam parser\n",
    "        self.bam = pysam.AlignmentFile(self.bam_file)\n",
    "    def peak_counts(self,peak) :\n",
    "        chromosome,start,end = peak\n",
    "        chromosome = str(chromosome)\n",
    "        # use the BigWig parser to get the stats of the peak\n",
    "        return self.bam.count(chromosome,start,end)\n",
    "    def __del__(self) :\n",
    "        self.bam.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_peak_counts(peaks,condition) :\n",
    "    npeaks = peaks.size\n",
    "    pcounts = np.zeros(npeaks)\n",
    "    for i,peak in enumerate(peaks) :\n",
    "        pcounts[i] = condition.peak_counts(peak)\n",
    "    return pcounts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use my lovely \"Condition\" class to get my data nicely packed into convenient data structures\n",
    "high       = Condition('high'   ,'all_treated',0.05,'gv_107_01_01_chipseq')\n",
    "medium1    = Condition('medium1','4HCP'       ,0.10,'gv_108_01_01_chipseq')\n",
    "medium2    = Condition('medium2','3HCP'       ,0.50,'gv_109_01_01_chipseq')\n",
    "low        = Condition('low'    ,'1HCP'       ,10.0,'gv_111_01_01_chipseq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high.avH  = average_peak_counts(high.peaks,high)\n",
    "high.avM1 = average_peak_counts(medium1.peaks,high)\n",
    "high.avM2 = average_peak_counts(medium2.peaks,high)\n",
    "high.avL  = average_peak_counts(low.peaks,high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium1.avH  = average_peak_counts(high.peaks,medium1)\n",
    "medium1.avM1 = average_peak_counts(medium1.peaks,medium1)\n",
    "medium1.avM2 = average_peak_counts(medium2.peaks,medium1)\n",
    "medium1.avL  = average_peak_counts(low.peaks,medium1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium2.avH  = average_peak_counts(high.peaks,medium2)\n",
    "medium2.avM1 = average_peak_counts(medium1.peaks,medium2)\n",
    "medium2.avM2 = average_peak_counts(medium2.peaks,medium2)\n",
    "medium2.avL  = average_peak_counts(low.peaks,medium2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low.avH  = average_peak_counts(high.peaks,low)\n",
    "low.avM1 = average_peak_counts(medium1.peaks,low)\n",
    "low.avM2 = average_peak_counts(medium2.peaks,low)\n",
    "low.avL  = average_peak_counts(low.peaks,low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"           avH     avM1    avM2     avL\"\n",
    "print \"High    :   %.3f    %.3f    %.3f     %.3f\"%(high.avH,high.avM1,high.avM2,high.avL)\n",
    "print \"Medium1 :   %.3f    %.3f    %.3f     %.3f\"%(medium1.avH,medium1.avM1,medium1.avM2,medium1.avL)\n",
    "print \"Medium2 :   %.3f    %.3f    %.3f     %.3f\"%(medium2.avH,medium2.avM1,medium2.avM2,medium2.avL)\n",
    "print \"Low     :   %.3f    %.3f    %.3f     %.3f\"%(low.avH,low.avM1,low.avM2,low.avL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [high,medium1,medium2,low]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nconditions = len(conditions)\n",
    "H_to_L = np.zeros(nconditions)\n",
    "M1_to_L = np.zeros(nconditions)\n",
    "M2_to_L = np.zeros(nconditions)\n",
    "for i,condition in enumerate(conditions) :\n",
    "    H_to_L[i] = condition.avH/condition.avL\n",
    "    M1_to_L[i] = condition.avM1/condition.avL\n",
    "    M2_to_L[i] = condition.avM2/condition.avL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrations = [condition.concentration for condition in conditions]\n",
    "plt.loglog(concentrations,H_to_L,label='High')\n",
    "plt.loglog(concentrations,M1_to_L,label='Medium1')\n",
    "plt.loglog(concentrations,M2_to_L,label='Medium2')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of this analysis, by using the ratio between the number of reads instead of the peak quality, shows that there is an interesting non-monotonic dependence of the ratio on the concentration.\n",
    "\n",
    "## A model explanation\n",
    "\n",
    "Let's think for a moment that this effect is real. I want to look at possible reasons why this can be the case. I'll turn back to the chair model and look at non-uniform transition matrices.\n",
    "\n",
    "### Array init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init constants of the system\n",
    "N = 500                                   # number of equivalent systems\n",
    "n = 340                                   # number of sites in each system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Msites = np.arange(0,n,10)\n",
    "Hsites = np.arange(5,n,10)\n",
    "site_taus = np.ones(n)\n",
    "site_taus[Msites] = 5.0\n",
    "site_taus[Hsites] = 20.0\n",
    "# plot it\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "x = np.arange(n)\n",
    "plt.bar(x,site_taus[x])\n",
    "plt.xlabel(\"Site index\")\n",
    "plt.ylabel(r\"$\\tau$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lsites = range(n)\n",
    "for site in Hsites :\n",
    "    Lsites.remove(site)\n",
    "for site in Msites :\n",
    "    Lsites.remove(site)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I init the transition matrices: I'll init the uniform matrix so I can have a comparison reference result. Before doing that I want to add another piece to my codebase: a class to neatly contain all the tests I'll do with a given transition matrix hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JumpingModel :\n",
    "    def __init__ (self,T,site_taus) :\n",
    "        self.T = T\n",
    "        self.site_taus = site_taus\n",
    "        self.omega_t = {}\n",
    "        self.occupancy = {}\n",
    "    def run(self,nsteps,mu,sigma,omega_t_initial) :\n",
    "        self.omega_t[mu] = pr_peaks.run_chair_simulation(nsteps,\n",
    "                                                         omega_t_initial,\n",
    "                                                         self.T,\n",
    "                                                         self.site_taus)\n",
    "        self.occupancy[mu] = self.omega_t[mu].sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 1000\n",
    "sigma = None\n",
    "mus = [1,2,5,10,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Tflat = np.ones((n,n))/n\n",
    "flat = JumpingModel(Tflat,site_taus)\n",
    "for mu in mus :\n",
    "    print \"Mu = %d\"%(mu)\n",
    "    omega_t_initial = pr_peaks.init_omega_t(N,n,mu,sigma)\n",
    "    flat.run(nsteps,mu,sigma,omega_t_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HL : high-to-low loops\n",
    "I want to see now what happens if I introduce a link between every H site and an L site (picked randomly).\n",
    "\n",
    "The idea here is that if there is more probability that once an H site is free, there will immediately be a searcher jumping to it, an effect which will be more evident when there are more searchers present in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the transition matrix\n",
    "THL = np.ones((n,n))\n",
    "nH = len(Hsites)\n",
    "target_L_sites = np.random.choice(Lsites,size=nH)\n",
    "for i in range(nH) :\n",
    "    i1 = Hsites[i]\n",
    "    i2 = target_L_sites[i]\n",
    "    # for i2 in Lsites :\n",
    "    THL[i1,i2] += 1\n",
    "    THL[i2,i1] += 1\n",
    "THL = mbt.row_normalize_matrix(THL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "HL = JumpingModel(THL,site_taus)\n",
    "for mu in mus :\n",
    "    print \"Mu = %d\"%(mu)\n",
    "    omega_t_initial = pr_peaks.init_omega_t(N,n,mu,sigma)\n",
    "    HL.run(nsteps,mu,sigma,omega_t_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axarr = plt.subplots(len(mus),2,figsize=(15,5))\n",
    "x = np.arange(n)\n",
    "show_xaxis=False\n",
    "for i,mu in enumerate(mus) :\n",
    "    # with flat transition probability\n",
    "    ax = axarr[i,0]\n",
    "    if i==len(mus)-1 :\n",
    "        show_xaxis=True\n",
    "    mbt.line_plot(ax,x,flat.occupancy[mu],show_xaxis=show_xaxis,color='b')\n",
    "    ax.text(0.8,0.8,r'$\\mu = %.1f$'%(mu),transform=ax.transAxes,fontsize=18)\n",
    "    # with HL loop\n",
    "    ax = axarr[i,1]\n",
    "    mbt.line_plot(ax,x,HL.occupancy[mu],show_xaxis=show_xaxis,color='r')\n",
    "    ax.text(0.8,0.8,r'$\\mu = %.1f$'%(mu),transform=ax.transAxes,fontsize=18)\n",
    "            \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform the ratio of the H to L peaks in the two cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat.H_to_L = np.zeros(len(mus))\n",
    "HL.H_to_L = np.zeros(len(mus))\n",
    "for i,mu in enumerate(mus) :\n",
    "    flat.avH = flat.occupancy[mu][Hsites].mean()\n",
    "    flat.avL = flat.occupancy[mu][Lsites].mean()\n",
    "    HL.avH = HL.occupancy[mu][Hsites].mean()\n",
    "    HL.avL = HL.occupancy[mu][Lsites].mean()\n",
    "    flat.H_to_L[i] = flat.avH/flat.avL\n",
    "    HL.H_to_L[i] = HL.avH/HL.avL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mus,flat.H_to_L,'r')\n",
    "plt.plot(mus,HL.H_to_L,'b')\n",
    "plt.xlabel(r'$\\mu$')\n",
    "plt.ylabel('H to L ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HH model\n",
    "Now let's examine another model: where all the H sites are avid and share contacts between themselves, and leave everyone else thirsty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the transition matrix\n",
    "THH = np.ones((n,n))\n",
    "nH = len(Hsites)\n",
    "for i in range(nH) :\n",
    "    for j in range(i,nH) :\n",
    "        THH[i,j] += 1\n",
    "        THH[j,i] += 1\n",
    "THH = mbt.row_normalize_matrix(THH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "HH = JumpingModel(THH,site_taus)\n",
    "for mu in mus :\n",
    "    print \"Mu = %d\"%(mu)\n",
    "    omega_t_initial = pr_peaks.init_omega_t(N,n,mu,sigma)\n",
    "    HH.run(nsteps,mu,sigma,omega_t_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axarr = plt.subplots(len(mus),2,figsize=(15,5))\n",
    "x = np.arange(n)\n",
    "show_xaxis=False\n",
    "for i,mu in enumerate(mus) :\n",
    "    # with flat transition probability\n",
    "    ax = axarr[i,0]\n",
    "    if i==len(mus) :\n",
    "        show_xaxis=True\n",
    "    mbt.line_plot(ax,x,flat.occupancy[mu],show_xaxis=show_xaxis,color='b')\n",
    "    ax.text(0.8,0.8,r'$\\mu = %.1f$'%(mu),transform=ax.transAxes,fontsize=18)\n",
    "    # with HL loop\n",
    "    ax = axarr[i,1]\n",
    "    mbt.line_plot(ax,x,HH.occupancy[mu],show_xaxis=show_xaxis,color='r')\n",
    "    ax.text(0.8,0.8,r'$\\mu = %.1f$'%(mu),transform=ax.transAxes,fontsize=18)\n",
    "            \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HH.H_to_L = np.zeros(len(mus))\n",
    "for i,mu in enumerate(mus) :\n",
    "    HH.avH = HH.occupancy[mu][Hsites].mean()\n",
    "    HH.avL = HH.occupancy[mu][Lsites].mean()\n",
    "    HH.H_to_L[i] = HH.avH/HH.avL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mus,flat.H_to_L,'r')\n",
    "plt.plot(mus,HH.H_to_L,'b')\n",
    "plt.xlabel(r'$\\mu$')\n",
    "plt.ylabel('H to L ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the conclusion of all this part is that the various models have certain features that are dependent on the choice of the parameters that one chooses. In this case one can only speculate that there is a certain combination of paramters that leads to the observed non-monotonic behaviour that I observed in the ChIP-seq data.\n",
    "\n",
    "The next, important step is to look at a simpler system that can be analyzed in terms of fewer parameters that can then be easily related to macroscopic, measurable features in the experimental system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
