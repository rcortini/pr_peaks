{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mybiotools as mbt\n",
    "import pr_peaks\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-02-28 Hints of good direction\n",
    "\n",
    "I found that the tetramerization hypothesis might explain the h-enhancement effect. I looked at whther there is any evidence for the effect in the Hi-C maps, but this has proven difficult. Now I want to try to see whether there is any evidence for this by looking at the population of the individual peaks.\n",
    "\n",
    "First, I'll look at what happens in the theory, when there is contact between two sites and there is a boost in the stability of the complex. What does the population of the sites in contact look like, as a function of the number of searchers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(85498)\n",
    "\n",
    "# general simulation parameters\n",
    "nsteps = 100000\n",
    "n = 100\n",
    "boost = 4.0\n",
    "mus = np.arange(1,20,2)\n",
    "\n",
    "# init site_taus\n",
    "Hsites = [2,6,10,40,50,60,70,80]\n",
    "Lsites = [i for i in xrange(n) if i not in Hsites]\n",
    "site_taus = 2.0*np.ones(n)\n",
    "site_taus[Hsites] = 20.0\n",
    "\n",
    "# init contact lists\n",
    "nocontacts = [[] for i in xrange(n)]\n",
    "HHcontact = [[] for i in xrange(n)]\n",
    "HHcontact[Hsites[0]] = [Hsites[1]]\n",
    "HHcontact[Hsites[1]] = [Hsites[0]]\n",
    "\n",
    "# init the Jumping Models\n",
    "uniform = pr_peaks.JumpingModel(nocontacts,site_taus,boost)\n",
    "HH = pr_peaks.JumpingModel(HHcontact,site_taus,boost)\n",
    "\n",
    "# cycle on mu values\n",
    "for mu in mus :\n",
    "    # init omega_t\n",
    "    omega_t_initial = pr_peaks.init_omega_t(n,mu)\n",
    "    mbt.log_message('Uniform','mu = %d'%(mu))\n",
    "    uniform.run(nsteps,omega_t_initial)\n",
    "    mbt.log_message('HH     ','mu = %d'%(mu))\n",
    "    HH.run(nsteps,omega_t_initial)\n",
    "    \n",
    "# aftermath\n",
    "pr_peaks.H_to_L(uniform,Hsites,Lsites)\n",
    "pr_peaks.H_to_L(HH,Hsites,Lsites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data, let's look at the following thing for each of the sites: the average count as a function of the number of searchers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmus = len(mus)\n",
    "nH   = len(Hsites)\n",
    "nL   = len(Lsites)\n",
    "for model in [uniform,HH] :\n",
    "    model.Hsites_theta = np.zeros((nmus,nH))\n",
    "    model.H_to_L_individual = np.zeros((nmus,nH))\n",
    "    for i,mu in enumerate(mus) :\n",
    "        model.Hsites_theta[i,:] = model.theta[mu][Hsites]\n",
    "        averageL = model.theta[mu][Lsites].mean()\n",
    "        model.H_to_L_individual[i,:] = model.Hsites_theta[i,:]/averageL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axarr = plt.subplots(2,2,figsize=(10,10))\n",
    "for j in xrange(nH) :\n",
    "    if j==0 or j==1 :\n",
    "        color='r'\n",
    "    else :\n",
    "        color='k'\n",
    "    axarr[0,0].plot(mus,uniform.Hsites_theta[:,j],color=color)\n",
    "    axarr[0,1].plot(mus,HH.Hsites_theta[:,j],color=color)\n",
    "    axarr[1,0].plot(mus,uniform.H_to_L_individual[:,j],color=color)\n",
    "    axarr[1,1].plot(mus,HH.H_to_L_individual[:,j],color=color)\n",
    "axarr[0,0].set_title('No contacts',fontsize=18)\n",
    "axarr[0,1].set_title('With contacts',fontsize=18)\n",
    "for ax in axarr[0,:] :\n",
    "    ax.set_ylabel(r'$\\theta$')\n",
    "for ax in axarr[1,:] :\n",
    "    ax.set_ylabel(r'H to L ratio')\n",
    "    ax.set_xlabel(r'$\\mu$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the difference here is quite spectacular. The population of the sites that have contacts is growing with the number of searchers, but all the other sites have a uniform decrease. Does this happen also for our beloved data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "high       = pr_peaks.Condition('high'   ,'all_treated',0.05,'gv_107_01_01_chipseq')\n",
    "medium1    = pr_peaks.Condition('medium1','4HCP'       ,0.10,'gv_108_01_01_chipseq')\n",
    "medium2    = pr_peaks.Condition('medium2','3HCP'       ,0.50,'gv_109_01_01_chipseq')\n",
    "medium3    = pr_peaks.Condition('medium3','3HCP'       ,1.00,'gv_110_01_01_chipseq')\n",
    "low        = pr_peaks.Condition('low'    ,'1HCP'       ,10.0,'gv_111_01_01_chipseq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate the number of counts corresponding to the High peaks, \n",
    "# as a function of the concentration of hormone\n",
    "Hpeaks = high.peaks\n",
    "Lpeaks = low.peaks\n",
    "conditions = [high,medium1,medium2,medium3,low]\n",
    "nconditions = len(conditions)\n",
    "nHpeaks = Hpeaks.size\n",
    "\n",
    "# init the arrays\n",
    "Hpeaks_count = np.zeros((nHpeaks,nconditions))\n",
    "averageL = np.zeros(nconditions)\n",
    "H_to_L_individual = np.zeros((nHpeaks,nconditions))\n",
    "\n",
    "# fill the arrays\n",
    "for j,condition in enumerate(conditions) :\n",
    "    averageL[j] = pr_peaks.average_peak_counts(Lpeaks,condition)\n",
    "    for i,peak in enumerate(Hpeaks) :\n",
    "        Hpeaks_count[i,j] = condition.peak_counts(peak)\n",
    "        H_to_L_individual[i,j] = Hpeaks_count[i,j]/averageL[j]kj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrations = np.array([c.concentration for c in conditions])\n",
    "for j in xrange(100) :\n",
    "    plt.loglog(concentrations,H_to_L_individual[j,:])#/H_to_L_individual[j,0])\n",
    "plt.xlabel('Concentration [nM]')\n",
    "plt.ylabel('Normalized H to L ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this data it is clear that there are many (if not all) peaks that increase their individual H to L ratio. It is not clear whether there are any of these peaks that do not. I'll try to look at the correlations between the individual peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = np.zeros((nHpeaks,nHpeaks))\n",
    "for i in xrange(nHpeaks) :\n",
    "    for j in xrange(i,nHpeaks) :\n",
    "        c = np.corrcoef(H_to_L_individual[i,:],H_to_L_individual[j,:])[0,1]\n",
    "        corrmat[i,j] = corrmat[j,i] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start,end = 50,60\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,10))\n",
    "cb = ax.matshow(corrmat[start:end,start:end])\n",
    "cax = plt.colorbar(cb)\n",
    "yticks = range(start,end)\n",
    "ax.set_yticks(range(len(yticks)))\n",
    "ax.set_yticklabels([str(Hpeaks[i]) for i in yticks])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pattern is not easily understandable. Maybe has something to do with TADs? What about inter-chromosomal correlations?\n",
    "\n",
    "I'll try to look at the various values of the concentrations and see the distributions of the H to L ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kH_to_L = []\n",
    "for i in xrange(concentrations.size) :\n",
    "    kH_to_L.append(gaussian_kde(H_to_L_individual[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,50,1)\n",
    "colors = ['b','r','g','k','xkcd:light blue']\n",
    "for i in xrange(concentrations.size) :\n",
    "    plt.plot(x,kH_to_L[i](x),label='c = %.2f'%(concentrations[i]),linewidth=3,\n",
    "            color=colors[i])\n",
    "plt.xlabel('Number of reads in H peaks')\n",
    "plt.ylabel('Distribution')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll look at the most anticorrelated pair of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j = np.unravel_index(corrmat.argmin(),corrmat.shape)\n",
    "plt.semilogx(concentrations,H_to_L_individual[i,:],'o--')\n",
    "plt.semilogx(concentrations,H_to_L_individual[j,:],'o--')\n",
    "plt.xlabel('Concentration [nM]')\n",
    "plt.ylabel('H to L ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I plot the profile that attains the highest value of the H to L ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j = np.unravel_index(H_to_L_individual.argmax(),H_to_L_individual.shape)\n",
    "plt.semilogx(concentrations,H_to_L_individual[i,:],'o--')\n",
    "plt.xlabel('Concentration [nM]')\n",
    "plt.ylabel('H to L ratio')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
